
```{r, include = FALSE}
ottrpal::set_knitr_image_path()

img_path <- "resources/images/pop_structure"
data_path <- "resources/data/pop_structure"
```

# Population structure

In this lab, we'll implement two common approaches for measuring and visualizing population structure: F~ST~ and principal component analysis (PCA).


## Learning objectives

After completing this chapter, you'll be able to:

1. Subset and annotate tabular data in R.
2. Measure population differentiation in populations.
3. Visualize the results of a principal component analysis.


## Background

### What is a population?

In the field of population genetics, the term "population" refers to a group of interbreeding individuals. The delineation of a population (as well as "subpopulation" and "superpopulation") is subjective. Groups exchange migrants at different rates (a process called "gene flow"), and there is no definitive boundary for determining whether groups of individuals constitute separate populations.

Often the terms population and subpopulation are used interchangeably. In this lab the terms population and subpopulation are used in a hierarchical sense where a subpopulation is group of individuals within a population. These individuals may be grouped because they show greater genetic similarity to each other than when compared to another subgroup within the larger population. However, even within this lab, these terms are subjective and interchangeable. Additionally, superpopulation is used in a hierarchical sense, specifically meaning a group of populations that originate from similar demographic areas. For example, the Yoruba (YRI) population (in Ibidan, Nigeria) and the Esan (ESN) population (in Nigeria) are joined with several other populations located in continental Africa to form the AFR or African superpopulation. Because the 1000 genomes project (1KGP) defines the population and superpopulation of each of its samples, population and superpopulation will not be used interchangeably within this lab.

### What is population structure?

"Structure" refers to the idea that however they are defined, populations have differing levels of separation and gene flow when compared to other populations. Specifically, individuals within a population tend to be more closely related (or share greater genetic similarity with each other) than individuals in different populations. These differences are manifested through differences in allele frequencies among populations and result from genetic drift, natural selection, and other evolutionary forces impacting these groups distinctly. These differences in allele frequencies can be measured and visualized, revealing evolutionary relationships among populations (which groups share more recent common ancestors), as well as evidence of past episodes of natural selection.

For a given variant that is present in two separate, but related populations, we might ask if the variant first arose in a common ancestor of both populations (prior to their splitting) or rather if the variant arose independently in both populations (post their splitting). ...  More info on this ...

### Geography of Genetic Variants Browser

... what is the browser ...
... what is it useful for ...
... how is it related to this lab ...
... WALKTHROUGH using the browser ...


## Setup

### R packages

Load these libraries to use for the rest of the lab:

```{r, results = FALSE, message = FALSE, warning = FALSE}
library(vcfR)
library(tidyverse)
```

### Data

### `random_snippet.vcf`

For this lab, we will be working with genetic variants. A record of these variants are stored in a `.vcf` file (`vcf` = "variant call format file"). [As explained by this resource](https://www.internationalgenome.org/wiki/Analysis/Variant%20Call%20Format/vcf-variant-call-format-version-40/), a`.vcf` file has a multi-line metadata header, a data header line, and then data lines. 

The **metadata header lines** start with `##` and provide meta-information specific to the file such as the VCF format version number, when the file was created, what source made the file, if it was quality checked, etc. These lines also may include descriptions of the FILTER, INFO, and FORMAT columns in the data lines. For example, the INFO column likely includes entries for several pieces of information such as the variant's allele frequency, population specific estimates of the variant's allele frequency, etc. Each piece of information that is provided in the INFO column will have its own description line in the metadata header. 

The **data header line** starts with `#` and lists at least the 8 required columns for a VCF file. It may include the FORMAT column if genotype data is included in the file. If genotype data is included, it'll also list the sample/individual IDs. 

There are multiple **data lines**. Each data line has information pertaining to a single variant. There is required info about variant location, identity, etc. and, depending on the file, the data lines may or may not contain genotype information for specific samples or individuals. The required columns are 

* CHROM -- the chromosome where the variant occurs
* POS -- the position at which the variant occurs
* ID
* REF -- the reference base(s) of the allele
* ALT -- the alternate non-reference allele(s) called on at least one o the samples 
* QUAL
* FILTER
* INFO -- the additional info entries discussed earlier like allele frequency, etc.

These required columns are also referred to as the 
"fixed information" columns.

If there's missing/not provided data for any of these required columns for a given variant, a `.` will be used.

If genotype information is provided for samples, these will be included after the FORMAT column, with a column for each included sample.

For a more comprehensive description of a `.vcf` file, be sure to consult the [example previously linked above](https://www.internationalgenome.org/wiki/Analysis/Variant%20Call%20Format/vcf-variant-call-format-version-40/) or the [samtools VCF manual](https://samtools.github.io/hts-specs/VCFv4.3.pdf).

The beginning of the `.vcf` that will be used for this lab looks like the following. Observe that this file does contain the genotype information for specific individuals. And unlike the example given in the resource above, only the genotype is provided for each individual (as opposed to including genotype quality scores, read depth, etc.). The genotypes are encoded as 0|0, 0|1, 1|0, or 1|1.

* 0|0 corresponds to a sample being homozygous reference for a variant
* 0|1 or 1|0 correspond to a sample being heterozygous alternate for a variant
* 1|1 corresponds to a sample being homozygous alternate for a variant

We also see that the INFO column does provide information about the variant's allele frequency. This will be important when we filter the data to include only "common variation."

![VCF file example](resources/images/pop_structure/vcf_head.png){width=50%}

### `integrated_call_samples.panel` 

For every individual with genotype/genetic variant data, the 1000 Genomes Project also provides metadata concerning the population and superpopulation of each individual. [A breakdown of these "codes" can be found here](https://m.ensembl.org/Help/Faq?id=532). Briefly, the 5 superpopulations are 

* EAS - East Asian
* EUR - European
* AFR - African
* AMR - Admixed American
* SAS - South Asian

`integrated_call_samples.panel` provides the superpopulation annotations for each sample in the `random_snippet.vcf` file. The four columns in this annotation file are `sample`, `pop`, `super_pop`, and `gender`.

* `sample` provides the name of the sample, matching the sample name in the `vcf` file. *(Because this information is shared between the files, later when we want to join or combine information from both files, we'll want to use this column.)*
* `pop` provides the population from which the sample originates
* `super_pop` provides the superpopulation of that population
* `gender` provides the sex of the sample.


## Reading the data

### Genotype data (`.vcf`)

We'll use the package `vcfR` to read the `vcf` file. However, the read function returns an object that isn't super helpful for visualization or data analysis. Therefore, we'll also use the `vcfR2tidy` function in order to convert the *vcfR object* into *tidy data frames* suitable for visualization and analysis with R. Specifically, vcfR2tidy returns an object with 3 elements, each a *tidy data frame* (`fix`, `gt`, and `meta`)

  * `fix` is a data frame of the "fixed information columns" containing information on variant location, identity, allele frequency, etc.
  * `gt` is another data frame of the genotype-related fields (if the file has genotype info for the samples).
  * `meta` is also a data frame containing all the INFO and FORMAT information from the multi-line metadata header.

Note: We have to tell this `vcfR2tidy` function to make all the allele frequencies numeric (or decimal/non-integer) values. We do this with the `info_types` argument.

```{r load_andtidy_data}
vcf <- read.vcfR(file = "resources/data/pop_structure/random_snippet.vcf")
vcf_tidy <- vcfR2tidy(vcf, info_types = c(AF = "n",
                                          EAS_AF = "n",
                                          EUR_AF = "n",
                                          AFR_AF = "n",
                                          AMR_AF = "n",
                                          SAS_AF = "n"))

```

### Population metadata (`.panel`)

To load the population annotations for the 1KGP samples, we use a baseR function `read_tsv` (which is used to read in tab-delimited files). 

```{r load_pop_annot, warning=FALSE, message=FALSE}
pops_1kg <- read_tsv("resources/data/pop_structure/integrated_call_samples.panel")
```

## Tidying the data

### Subsetting to only "common variants"

We want to work with common variants for the rest of this lab. Common variants are those whose allele frequency in the population is greater than 0.5 but less than 0.95. ... why only work with common variation?...

To visualize the distribution of allele frequencies in the population, we'll use a histogram and the `fix` element from the `vcf_tidy` object. We're specifically storing this information in the `vcf_info` variable first. 

```{r visualize_AF}
vcf_info <- vcf_tidy$fix
message(paste0("Number of variants: ", nrow(vcf_info)))

ggplot(data = vcf_info, 
       aes(x=AF)) + 
  geom_histogram(bins=100) + 
  geom_vline(xintercept=0.05, linetype="dashed", color="blue") +
  geom_vline(xintercept=0.95, linetype="dashed", color="brown")
```

Currently, from this histogram, you can see that our data has allele frequencies (AF) ranging from 0 to 1 with an exponential decay in AF, the majority being near 0, but less than 0.05 (the dashed blue line). From the `nrow(vcf_info)`, we see that there are 10,000 variant total. 

Here we'll subset the original VCF to just common variation.

```{r common_variation}
common_var <- vcf[vcf_info$AF > 0.05 & vcf_info$AF < 0.95, ]
```
  
For visualization purposes we'll also subset the tidy `vcf_info` variable, storing the subset common variation data in the variable `common_var_info`. 

```{r common_variation_tidy}
common_var_info <- vcf_info[vcf_info$AF > 0.05 & vcf_info$AF < 0.95, ]
message(paste0("Number of common variants: ", nrow(common_var_info)))
```

```{r visualze_common_af}
ggplot(data = common_var_info, 
       aes(x=AF)) + 
  geom_histogram(bins=90) + 
  geom_vline(xintercept=0.05, linetype="dashed", color="blue") +
  geom_vline(xintercept=0.95, linetype="dashed", color="brown")

```
  
Now we see that our subset data only has allele frequencies ranging from just above 0.05 to just below 0.95 like we wanted. We still observe an exponential decay in AF. We also observe that only 960 SNPs remain after filtering to only include common variants.

### Annotating the samples with superpopulation labels  
          
```{r sample_annotation}
sample_annotation <- tibble(sample = unique(vcf_tidy$gt$Indiv))
sample_annotation <- left_join(sample_annotation, pops_1kg, by="sample")
sample_annotation %>% head()
```


## Calculating F~ST~

~ST~ is a statistic which quantifies genotypic variance in subpopulations ("S") as compared to the total ("T") population. One way of conceptualizing F~ST~ is based on the deficiency of heterozygotes ("H") observed in a population relative to the proportion that would be expected under random mating (i.e., no population structure).

H = 2pq, where p is the frequency of allele A and q is the frequency of allele a. 

$$
F_{ST} = (H_T - mean(H_S)) / H_T
$$

In practical terms, this statistic is a way of measuring the amount by which allele frequencies vary among populations. See [this Nature Review Genetics article](https://pubmed.ncbi.nlm.nih.gov/19687804/) for a more thorough discussion on the derivation, use, and interpretation of F~ST~ and related statistics such as G~ST~, R~ST~, and Q~ST~.

G~ST~ was introduced as a modification to F~ST~ that considers when there are more than two alleles at a given locus. However, if there are only two alleles at a given locus, F~ST~ and G~ST~ are equivalent. Given this, we will use the G~ST~ statistic that is computed by the `genetic_diff()` function in the `vcfR` library. 

```{r}
?genetic_diff
```

As we can see from the documentation, the input to this function is 
*   a `vcfR` object 
*   "pops" a "factor indicating populations". 

We have two different `vcfR` objects from earlier. One is `vcf_tidy` which contains every variant from the input `.vcf` file. The other is `common_var` which contains only the common variants from the input `.vcf` file. Since we want to work with only common variatns, we'll use `common_var`.

In practice, "pops"  will be a vector of population labels for the samples the `vcfR` object contains, and the labels will be of type "factor". A factor type in R limits a variable to a specific set of possible values. So a vector variable of type factor uses those specific possible values to categorize and store all the data in the vector. (You can read more about [R's variable types here](https://www.cyclismo.org/tutorial/R/types.html).). We have the population labels for each sample in the `sample_annotation` data frame, specifically the `pop` column. We will ensure the labels are type "factor" using the `as.factor()` function. 
 

```{r }
gst_results <- genetic_diff(common_var, as.factor(sample_annotation$pop)) %>% 
  arrange(-Gst)

gst_results %>% 
  head()
```

```{r}
gst_results %>% 
  tail()
```

... Describe the results and point out the Gst column specifically ...

**Coding practice:** We would like to look at the distribution of the G~st~ values. A histogram is a natural choice for this visualization. Using the example allele frequency histograms from earlier and the gray boxes from the *Pattern code* below as a guide of where code needs to be added, fill in the following *Code block* and run it when you are ready.

*Pattern code*

| `ggplot(data = ` <span style="background: dimgray; color: dimgray"> __ </span> `,`
|         `aes(x = `<span style="background: dimgray; color: dimgray"> __ </span> `)) +`
|     <span style="background: dimgray; color: dimgray"> __ </span>`(bins = 30)`

<br /><br /><br />
*Code block*

```{r, eval = FALSE}
ggplot(data = ,
       aes(x = )) +
   (bins=30)
```

**Question:** Add a question about interpreting the distribution

***
<details><summary> Solution </summary>

```{r}
ggplot(data = gst_results, 
       aes(x=Gst)) +
  geom_histogram(bins=30)
```


... add interpretation ...

</details>
***


## Principal component analysis

Principal component analysis (PCA) is a way of representing high-dimensional data (i.e., data with many variables) in a smaller number of dimensions while still capturing important variation within the data. While the math is complex, it is helpful to consider its geometric interpretation. The first principal component is chosen as the vector through the cloud of data points that captures the greatest possible variance. The second principal component is the vector capturing the second greatest possible variance, with the added condition that this second vector must be perpendicular to the first vector. The same idea applies to the third, fourth, fifth, etc. principal components. We recommend looking at [this nice visual demonstration of PCA](http://setosa.io/ev/principal-component-analysis/). 
In the case of PCA applied to genetic data, the dimensions/variables of interest are the SNPs at which we have measured genotypes for many individuals. SNP arrays typically measure genotypes at millions of SNPs, so PCA is a useful method of dimension reduction to visualize the data in two dimensions.

The genotype for any given biallelic SNP can be represented by a 0, 1, or 2.

* 0 represents homozygous reference (genotype of 0|0)
* 1 represents heterozygous alternate (genotype of 0|1 or 1|0)
* 2 represents homozygous alternate genotypes (genotypes of 1|1)

The genotypes of $m$ individuals for any given biallelic SNP can thus be represented as a vector (length $m$) of 0s, 1s, and 2s. If considering $n$ number of biallelic SNPs, there will be $n$ vectors. The full dataset thus represents an $m x n$ matrix, where $m$ is the number of individuals and $n$ is the number of SNPs.

Our data set is currently $n x m$ with the rows representing the SNPs and the columns representing the samples/individuals. Therefore, we'll want to transpose the data, changing it from $n x m$ to $m x n$
... TALK about scaling ...

The function `extract.gt()` from `vcfR` generates a genotype matrix from a vcf object. However, it does not directly convert the genotypes to integers (0, 1, and 2) like we want. So, we also use a tidyverse function to convert or "recode" these genotype values within every column.   

```{r extract_genotype_numeric}

genotype_matrix <- extract.gt(common_var) %>% 
  as.data.frame() %>% 
  dplyr::mutate_at(vars(everything()), 
                   recode, "0|0" = 0, "1|0" = 1, "0|1" = 1, "1|1" = 2) %>%
  as.matrix()
```


Now we're ready to pass this matrix of integer genotypes to the pca function which is `prcomp` in R. Recall, the matrix of integer genotypes is $n x m$ (or number of SNPs $x$ number of individuals); therefore, we use the `t()` function to transpose the genotype matrix to be $m x n$ (or number of individuals $x$ number of SNPs). By default, `prcomp` will not scale the data, and we're fine with this because ....

```{r pca_genotypes}
pca <- prcomp(t(genotype_matrix))
```

We want to make a nice dataframe that we can use for plotting the results of the PCA....

```{r pretty_pca_tibble}
pca_results <- tibble(sample = rownames(pca$x),
                      PC1 = pca$x[,1],
                      PC2 = pca$x[,2],
                      PC3 = pca$x[,3])

pca_results <- left_join(pca_results, sample_annotation, by = "sample")
```

And it would be cool to see what percentage of variance is explained by each of the principal components ...

```{r variance_explained}
var_explained <- pca$sdev^2/sum(pca$sdev^2)
pc1_ve <- round(var_explained[1]*100,1)
pc2_ve <- round(var_explained[2]*100,1)
pc3_ve <- round(var_explained[3]*100,1)
```

Then we can plot everything ...

```{r plot_pca}
ggplot(data = pca_results, 
       aes(x = PC1, y = PC2, color=super_pop)) + 
  geom_point() + 
  xlab(paste0("PC1: ", pc1_ve, " %")) + 
  ylab(paste0("PC2: ", pc2_ve, " %"))
```

**Coding practice:** We'd also like to visualize Principal Component 2 vs Principal Component 3. Using the example above and the gray boxes from the *Pattern code* below as a guide of where code needs to be added, fill in the following *Code block* and run it when you are ready.

*Pattern code*

| `ggplot(data = ` <span style="background: dimgray; color: dimgray"> __ </span> `,`
|         `aes(x = `<span style="background: dimgray; color: dimgray"> __ </span> `, y = ` <span style="background: dimgray; color: dimgray"> __ </span> `, color=super_pop)) +`
|     <span style="background: dimgray; color: dimgray"> __ </span>`() +`
|     `xlab(paste0("` <span style="background: dimgray; color: dimgray"> __ </span> ` :",` <span style="background: dimgray; color: dimgray"> __ </span>  `, " %")) +`
|     `ylab(paste0("` <span style="background: dimgray; color: dimgray"> __ </span> ` :",` <span style="background: dimgray; color: dimgray"> __ </span>  `, " %"))`

<br /><br /><br />
*Code block*

```{r codeblock_pca23, eval=FALSE}
ggplot(data = ,
       aes(x = , y=, color=super_pop)) + 
  () + 
  xlab(paste0(" : ", , " %")) + 
  ylab(paste0(" : ", , " %"))
```

**Question:** What superpopulations do you observe separating on PC3? 

***
<details><summary> Solution </summary>

```{r plot_pca23}
ggplot(data = pca_results,
       aes(x = PC2, y=PC3, color=super_pop)) + 
  geom_point() + 
  xlab(paste0("PC2: ", pc2_ve, " %")) + 
  ylab(paste0("PC3: ", pc3_ve, " %"))
```
We observe the SAS and AMR superpopulations separating from the AFR, EAS, and EUR superpopulations along PC3.

</details>
***


## Conclusion

something something


## Homework

### Projecting a new sample onto pre-defined principal component axes

1. There are 2548 individuals in the dataset, `genotype_matrix`. First, "remove" or "hold out" a random $1%$ or 25 of those individuals, placing them into a "test set". Assign the remaining $99%$ (2523 individuals) to the "training set".

To make your homework reproducible, you'll want to set the random seed so that every time the code is run, the same "random" steps are taken ... explain this better ...

You can randomly select 25 individuals by picking 25 random numbers from 1 to 2548... how much of the below code should we just give them?...

This code block here is getting the indices and the metadata for the held out data
```{r}
set.seed(15)
held_out_individuals_indices <- sample(1:ncol(genotype_matrix), size=25)
held_out_individuals_samplenames <- colnames(genotype_matrix)[held_out_individuals_indices]
held_out_individuals_superpops <- unlist(lapply(1:length(held_out_individuals_samplenames), function(x) sample_annotation[which(sample_annotation$sample == held_out_individuals_samplenames[x]), "super_pop"])) %>% `names<-`(held_out_individuals_samplenames) %>% as.data.frame() %>% `colnames<-`(c("super_pop"))
```

This code block here is separating the genotype data for the training and the held out data
```{r}
held_out_gt <- genotype_matrix[,held_out_individuals_indices]
dim(held_out_gt) #prints out the dimensions/size -- observe 960 SNPs, 25 individuals
train_gt <- genotype_matrix[,setdiff(1:ncol(genotype_matrix), held_out_individuals_indices)]
dim(train_gt) #prints out the dimensions/size -- observe 960 SNPs, 2523 individuals
```

2. Repeat PCA with the 2523 "training set" individuals.

```{r}
pca_repeat <- prcomp(t(train_gt))
pca_res_repeat <- tibble(sample = rownames(pca_repeat$x),
                      PC1 = pca_repeat$x[,1],
                      PC2 = pca_repeat$x[,2],
                      PC3 = pca_repeat$x[,3])

pca_res_repeat <- left_join(pca_res_repeat, sample_annotation, by = "sample")
```

```{r}
train_plot12 <- ggplot(data = pca_res_repeat, 
       aes(x = PC1, y = PC2, color=super_pop)) + 
  geom_point() + 
  xlab("PC1") + 
  ylab("PC2")

train_plot12

train_plot23 <- ggplot(data = pca_res_repeat, 
       aes(x = PC2, y = PC3, color=super_pop)) + 
  geom_point() + 
  xlab("PC2") + 
  ylab("PC3")

train_plot23
```

3. Project the "held out" 25 individuals on this repeated PCA from step 2.

(Both of the following options work equally well/same results)

```{r}
heldout_samples_pca <- predict(pca_repeat, t(held_out_gt))
```

or

```{r}
heldout_samples_pca_linalg <- scale(t(held_out_gt), pca_repeat$center, pca_repeat$scale) %*% pca_repeat$rotation 
```

4. Visually inspect the placement of each of these 25 individuals on the PCA plot and write a prediction for their superpopulation.

```{r}

heldout_pca_res <- tibble(sample = held_out_individuals_samplenames,
                      PC1 = heldout_samples_pca[,"PC1"],
                      PC2 = heldout_samples_pca[,"PC2"],
                      PC3 = heldout_samples_pca[,"PC3"],
                      super_pop = "Unknown")

for (i in 1:25){
  new_plot12 <- train_plot12 + geom_point(data = heldout_pca_res[i,], aes(x=PC1, y = PC2)) + geom_label(data = heldout_pca_res[i,], aes(x=PC1+1, y = PC2+1, label=sample))
  print(new_plot12)

  new_plot23 <- train_plot23 + geom_point(data = heldout_pca_res[i,], aes(x=PC2, y = PC3)) + geom_label(data = heldout_pca_res[i,], aes(x=PC2+1, y = PC3+1, label=sample))
  print(new_plot23)
}
```
```{r}

guess_df <- data.frame(sample = held_out_individuals_samplenames,
                       guess_super_pop = c("AMR", "EAS", "EUR", "EUR", "EAS", "AFR", "SAS", "EUR", "AFR", "AFR", "EAS", "EUR", "SAS", "EUR", "EAS", "AFR", "SAS", "AMR", "EAS", "AFR", "SAS", "EAS", "AFR", "EUR", "EAS"))
```

5. Use the annotation to compare your prediction with the true superpopulation for the 25 individuals. (Recall the true superpopulation is stored in `sample_annotation`)

```{r}
# guess_df$super_pop <- held_out_individuals_superpops
# num_correct <- sum(guess_df$guess_super_pop == guess_df$super_pop)
# if (num_correct != 25){
#   incorrect_samples <- guess_df$sample[which(guess_df$guess_super_pop != guess_df$super_pop)]
#   message("Incorrect sample(s): ") 
#   incorrect_samples
# } else { message("All guesses are correct!")}
```

6. Bonus/extra hard/optional: use k-means clustering to assign the 25 individuals to a superpopulation and then compare clustering's assignment with true superpopulation.

*   select some test data
*   Repeat PCA on the rest of the dataset
*   Project the held out sample points
*   Look at placement and predict the super population
*   Use the annotation to compare prediction with truth

### G_ST pairs of continental superpopulations (optional)

 or
 
### Thought question on ethics/proper interpretation